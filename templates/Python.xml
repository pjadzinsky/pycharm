<templateSet group="Python">
  <template name="pudb" value="import pudb&#10;pudb.set_trace()" description="import and set_trace" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="debug" value="#!/usr/bin/python&#10;import unittest&#10;&#10;from common import testing&#10;&#10;&#10;class TestClass(unittest.TestCase):&#10;    def test1(self):&#10;        pass&#10;        &#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    testing.run(concurrent=False)" description="template for debugging" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
  <template name="shebang" value="#!/usr/bin/env python&#10;# -*- coding: utf-8 -*-&#10;&#10;&#10;def main():&#10;    $END$&#10;    &#10;    &#10;if __name__ == &quot;__main__&quot;:&#10;    main()" description="add executable header" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
      <option name="Python_Class" value="false" />
    </context>
  </template>
  <template name="spark" value="from pyspark.sql import SparkSession&#10;from common.spark import spark_utils&#10;def main():&#10;    log_conf = spark_utils.DriverLoggingConfig()&#10;    spark = SparkSession.builder.appName(&quot;PythonPi&quot;).getOrCreate()&#10;    sc = spark.sparkContext&#10;    rdd = sc.parallelize(tasks)&#10;    &quot;&quot;&quot;&#10;    process rdd here&#10;    &quot;&quot;&quot;&#10;    spark.stop()" description="spark boiler plate" toReformat="false" toShortenFQNames="true">
    <context>
      <option name="Python" value="true" />
    </context>
  </template>
</templateSet>